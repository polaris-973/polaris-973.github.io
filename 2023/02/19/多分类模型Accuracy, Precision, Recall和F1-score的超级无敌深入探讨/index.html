<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Paddey&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Paddey&#039;s Blog"><meta name="msapplication-TileImage" content="https://polaris-973.oss-cn-shenzhen.aliyuncs.com/img/b9c9db0f589cd855eb655fce4054665.jpg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Paddey&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="多分类模型Accuracy, Precision, Recall和F1-score的超级无敌深入探讨前言众所周知，机器学习分类模型常用评价指标有Accuracy, Precision, Recall和F1-score，而回归模型最常用指标有MAE和RMSE。但是我们真正了解这些评价指标的意义吗？"><meta property="og:type" content="blog"><meta property="og:title" content="Paddey&#039;s Blog"><meta property="og:url" content="https://paddeyzhang.tech/2023/02/19/%E5%A4%9A%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8BAccuracy,%20Precision,%20Recall%E5%92%8CF1-score%E7%9A%84%E8%B6%85%E7%BA%A7%E6%97%A0%E6%95%8C%E6%B7%B1%E5%85%A5%E6%8E%A2%E8%AE%A8/"><meta property="og:site_name" content="Paddey&#039;s Blog"><meta property="og:description" content="多分类模型Accuracy, Precision, Recall和F1-score的超级无敌深入探讨前言众所周知，机器学习分类模型常用评价指标有Accuracy, Precision, Recall和F1-score，而回归模型最常用指标有MAE和RMSE。但是我们真正了解这些评价指标的意义吗？"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://pic2.zhimg.com/80/v2-0af2bd2decf49bbb45e31ef7091625e9_720w.jpg"><meta property="og:image" content="https://pic1.zhimg.com/80/v2-763b2bc2e358ead002eca8d94e104db4_720w.jpg"><meta property="og:image" content="https://www.zhihu.com/equation?tex=Accuracy+%3D+%5Cfrac%7BTP%2BTN%7D%7BTP%2BTN%2BFP%2BFN%7D"><meta property="og:image" content="https://www.zhihu.com/equation?tex=Precision+%3D+%5Cfrac%7BTP%7D%7BTP%2BFP%7D"><meta property="og:image" content="https://www.zhihu.com/equation?tex=Recall+%3D+%5Cfrac%7BTP%7D%7BTP%2BFN%7D"><meta property="og:image" content="https://www.zhihu.com/equation?tex=F1%5Ctext%7B-%7Dscore+%3D+%5Cfrac%7B2%5Ctimes+%5Ctext%7BPrecision%7D+%5Ctimes+%5Ctext%7BRecall%7D%7D%7B+%5Ctext%7BPrecision%7D%2B%5Ctext%7BRecall%7D%7D"><meta property="og:image" content="https://pic4.zhimg.com/80/v2-e1cf922d05b7e1bf266620577e6fd253_720w.jpg"><meta property="og:image" content="https://pic4.zhimg.com/80/v2-77e85aad7db38c1f4a2116af5fb10a5b_720w.jpg"><meta property="og:image" content="https://www.zhihu.com/equation?tex=Precision+%3D+%5Cfrac%7BTP%7D%7BTP%2BFP%7D+%3D+%5Cfrac%7B20%7D%7B20%2B50%7D+%3D+2%2F7"><meta property="og:image" content="https://www.zhihu.com/equation?tex=Recall+%3D+%5Cfrac%7BTP%7D%7BTP%2BFN%7D+%3D+%5Cfrac%7B20%7D%7B20%2B10%7D+%3D+2%2F3"><meta property="og:image" content="https://www.zhihu.com/equation?tex=P_%7Bcat%7D%3D8%2F15%2C+P_%7Bdog%7D+%3D+17%2F23%2CP_%7Bpig%7D%3D2%2F7"><meta property="og:image" content="https://www.zhihu.com/equation?tex=R_%7Bcat%7D%3D4%2F7%2C+R_%7Bdog%7D+%3D+17%2F32%2CR_%7Bpig%7D%3D2%2F3"><meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Ctext%7BMacro-Precision%7D+%3D+%5Cfrac%7B%7BP%7D_%7Bcat%7D+%2BP_%7Bdog%7D++%2BP_%7Bpig%7D+%7D%7B3%7D+%3D+0.5194"><meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Ctext%7BMacro-Recall%7D+%3D+%5Cfrac%7BR_%7Bcat%7D+%2B+R_%7Bdog%7D++%2BR_%7Bpig%7D+%7D%7B3%7D+%3D+0.5898"><meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Ctext%7BW%7D_%7Bcat%7D+%3A+%5Ctext%7BW%7D_%7Bdog%7D+%3A+%5Ctext%7BW%7D_%7Bpig%7D+%3D+%5Ctext%7BN%7D_%7Bcat%7D+%3A+%5Ctext%7BN%7D_%7Bdog%7D+%3A%5Ctext%7BN%7D_%7Bpig%7D++%3D+%5Cfrac%7B7%7D%7B26%7D+%3A+%5Cfrac%7B16%7D%7B26%7D%3A+%5Cfrac%7B3%7D%7B26%7D"><meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Ctext%7BWeighted-Precision%7D+%3D+%7BP%7D_%7Bcat%7D%5Ctimes+W_%7Bcat%7D+%2B++%7BP%7D_%7Bdog%7D%5Ctimes+W_%7Bdog%7D+%2B++%7BP%7D_%7Bpig%7D%5Ctimes+W_%7Bpig%7D+%3D+0.6314"><meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Ctext%7BWeighted-Recall%7D+%3D+%7BR%7D_%7Bcat%7D%5Ctimes+W_%7Bcat%7D+%2B++%7BR%7D_%7Bdog%7D%5Ctimes+W_%7Bdog%7D+%2B++%7BR%7D_%7Bpig%7D%5Ctimes+W_%7Bpig%7D+%3D+0.5577"><meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Ctext%7BMicro-Precision%7D+%3D+%5Cfrac%7B%7BTP%7D_%7Bcat%7D+%2B+%7BTP%7D_%7Bdog%7D+%2B+%7BTP%7D_%7Bpig%7D%7D%7B+%7BTP%7D_%7Bcat%7D+%2B+%7BTP%7D_%7Bdog%7D+%2B+%7BTP%7D_%7Bpig%7D%2B++%7BFP%7D_%7Bcat%7D+%2B+%7BFP%7D_%7Bdog%7D+%2B+%7BFP%7D_%7Bpig%7D%7D+%3D+0.5577+"><meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Ctext%7BMicro-Recall%7D+%3D+%5Cfrac%7B%7BTP%7D_%7Bcat%7D+%2B+%7BTP%7D_%7Bdog%7D+%2B+%7BTP%7D_%7Bpig%7D%7D%7B+%7BTP%7D_%7Bcat%7D+%2B+%7BTP%7D_%7Bdog%7D+%2B+%7BTP%7D_%7Bpig%7D%2B++%7BFN%7D_%7Bcat%7D+%2B+%7BFN%7D_%7Bdog%7D+%2B+%7BFN%7D_%7Bpig%7D%7D%3D0.5577"><meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Ctext%7BMicro-Precision%7D+%3D+%5Ctext%7BMicro-Recall%7D+%3D+%5Ctext%7BMicro-F1+score%7D+%3D+%5Ctext%7BAccuracy%7D+"><meta property="og:image" content="https://pic2.zhimg.com/80/v2-344f35ae60c0ad5eeb24a19aefa92f45_720w.jpg"><meta property="og:image" content="https://pic2.zhimg.com/80/v2-499a45ce0ed22859d425ca82467b813d_720w.jpg"><meta property="article:published_time" content="2023-02-19T14:25:29.963Z"><meta property="article:modified_time" content="2023-02-19T10:21:12.746Z"><meta property="article:author" content="paddeyzhang"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://pic2.zhimg.com/80/v2-0af2bd2decf49bbb45e31ef7091625e9_720w.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://paddeyzhang.tech/2023/02/19/%E5%A4%9A%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8BAccuracy,%20Precision,%20Recall%E5%92%8CF1-score%E7%9A%84%E8%B6%85%E7%BA%A7%E6%97%A0%E6%95%8C%E6%B7%B1%E5%85%A5%E6%8E%A2%E8%AE%A8/"},"headline":"Paddey's Blog","image":["https://pic2.zhimg.com/80/v2-0af2bd2decf49bbb45e31ef7091625e9_720w.jpg","https://pic1.zhimg.com/80/v2-763b2bc2e358ead002eca8d94e104db4_720w.jpg","https://pic4.zhimg.com/80/v2-e1cf922d05b7e1bf266620577e6fd253_720w.jpg","https://pic4.zhimg.com/80/v2-77e85aad7db38c1f4a2116af5fb10a5b_720w.jpg","https://pic2.zhimg.com/80/v2-344f35ae60c0ad5eeb24a19aefa92f45_720w.jpg","https://pic2.zhimg.com/80/v2-499a45ce0ed22859d425ca82467b813d_720w.jpg"],"datePublished":"2023-02-19T14:25:29.963Z","dateModified":"2023-02-19T10:21:12.746Z","author":{"@type":"Person","name":"paddeyzhang"},"publisher":{"@type":"Organization","name":"Paddey's Blog","logo":{"@type":"ImageObject","url":"https://polaris-973.oss-cn-shenzhen.aliyuncs.com/img/b9c9db0f589cd855eb655fce4054665.jpg"}},"description":"多分类模型Accuracy, Precision, Recall和F1-score的超级无敌深入探讨前言众所周知，机器学习分类模型常用评价指标有Accuracy, Precision, Recall和F1-score，而回归模型最常用指标有MAE和RMSE。但是我们真正了解这些评价指标的意义吗？"}</script><link rel="canonical" href="https://paddeyzhang.tech/2023/02/19/%E5%A4%9A%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8BAccuracy,%20Precision,%20Recall%E5%92%8CF1-score%E7%9A%84%E8%B6%85%E7%BA%A7%E6%97%A0%E6%95%8C%E6%B7%B1%E5%85%A5%E6%8E%A2%E8%AE%A8/"><link rel="icon" href="https://polaris-973.oss-cn-shenzhen.aliyuncs.com/img/b9c9db0f589cd855eb655fce4054665.jpg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="https://polaris-973.oss-cn-shenzhen.aliyuncs.com/img/b9c9db0f589cd855eb655fce4054665.jpg" alt="Paddey&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-02-19T14:25:29.963Z" title="2/19/2023, 22:25:29">2023-02-19</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-02-19T10:21:12.746Z" title="2/19/2023, 18:21:12">2023-02-19</time></span><span class="level-item">22 minutes read (About 3352 words)</span></div></div><div class="content"><h1 id="多分类模型Accuracy-Precision-Recall和F1-score的超级无敌深入探讨"><a href="#多分类模型Accuracy-Precision-Recall和F1-score的超级无敌深入探讨" class="headerlink" title="多分类模型Accuracy, Precision, Recall和F1-score的超级无敌深入探讨"></a>多分类模型Accuracy, Precision, Recall和F1-score的超级无敌深入探讨</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>众所周知，机器学习分类模型常用评价指标有Accuracy, Precision, Recall和F1-score，而回归模型最常用指标有MAE和RMSE。但是我们真正了解这些评价指标的意义吗？</p>
<span id="more"></span>
<p><strong>在具体场景（如不均衡多分类）中到底应该以哪种指标为主要参考呢？多分类模型和二分类模型的评价指标有啥区别？多分类问题中，为什么Accuracy = micro precision = micro recall = micro F1-score? 什么时候用macro, weighted, micro precision/ recall/ F1-score?</strong></p>
<p>主要分为以下两点：</p>
<ul>
<li><strong>二分类</strong>模型的常见指标<strong>快速回顾</strong></li>
<li><strong>多分类</strong>模型的常见指标<strong>详细解析</strong></li>
</ul>
<p>在探讨这些问题前，让我们先回顾一下最常见的指标Accuracy到底有哪些不足。</p>
<p>Accuracy是分类问题中最常用的指标，它计算了分类正确的预测数与总预测数的比值。但是，<strong>对于不平衡数据集而言，Accuracy并不是一个好指标</strong>。为啥？</p>
<p>假设我们有100张图片，其中91张图片是「狗」，5张是「猫」，4张是「猪」，我们希望训练一个三分类器，能正确识别图片里动物的类别。其中，狗这个类别就是大多数类 (majority class)。当大多数类中样本（狗）的数量远超过其他类别（猫、猪）时，如果采用Accuracy来评估分类器的好坏，那么即便模型性能很差 (如无论输入什么图片，都预测为「狗」)，也可以得到较高的Accuracy Score（如91%）。此时，虽然Accuracy Score很高，但是意义不大。<strong>当数据异常不平衡时，Accuracy评估方法的缺陷尤为显著。</strong></p>
<p>因此，我们需要引入Precision （精准度），Recall （召回率）和F1-score评估指标。考虑到二分类和多分类模型中，评估指标的计算方法<strong>略有不同</strong>，我们将其分开讨论。</p>
<h2 id="二分类模型的常见指标快速回顾"><a href="#二分类模型的常见指标快速回顾" class="headerlink" title="二分类模型的常见指标快速回顾"></a>二分类模型的常见指标快速回顾</h2><p>在二分类问题中，假设该样本一共有两种类别：Positive和Negative。当分类器预测结束，我们可以绘制出混淆矩阵（confusion matrix）。其中分类结果分为如下几种：</p>
<p><img src="https://pic2.zhimg.com/80/v2-0af2bd2decf49bbb45e31ef7091625e9_720w.jpg" alt="img"></p>
<ul>
<li>True Positive (TP): 把正样本成功预测为正。</li>
<li>True Negative (TN)：把负样本成功预测为负。</li>
<li>False Positive (FP)：把负样本错误地预测为正。</li>
<li>False Negative (FN)：把正样本错误的预测为负。</li>
</ul>
<p><img src="https://pic1.zhimg.com/80/v2-763b2bc2e358ead002eca8d94e104db4_720w.jpg" alt="img"></p>
<p>在二分类模型中，Accuracy，Precision，Recall和F1 score的定义如下：</p>
<p><img src="https://www.zhihu.com/equation?tex=Accuracy+%3D+%5Cfrac%7BTP%2BTN%7D%7BTP%2BTN%2BFP%2BFN%7D" alt="[公式]"></p>
<p><img src="https://www.zhihu.com/equation?tex=Precision+%3D+%5Cfrac%7BTP%7D%7BTP%2BFP%7D" alt="[公式]"></p>
<p><img src="https://www.zhihu.com/equation?tex=Recall+%3D+%5Cfrac%7BTP%7D%7BTP%2BFN%7D" alt="[公式]"></p>
<p><img src="https://www.zhihu.com/equation?tex=F1%5Ctext%7B-%7Dscore+%3D+%5Cfrac%7B2%5Ctimes+%5Ctext%7BPrecision%7D+%5Ctimes+%5Ctext%7BRecall%7D%7D%7B+%5Ctext%7BPrecision%7D%2B%5Ctext%7BRecall%7D%7D" alt="[公式]"></p>
<p>其中，Precision着重评估<strong>在预测为Positive的所有数据中，真实Positve的数据到底占多少？</strong>Recall着重评估：<strong>在所有的Positive数据中，到底有多少数据被成功预测为Positive?</strong></p>
<p>举个例子，一个医院新开发了一套癌症AI诊断系统，想评估其性能好坏。我们把病人得了癌症定义为Positive，没得癌症定义为Negative。那么， 到底该用什么指标进行评估呢？</p>
<p>如用Precision对系统进行评估，那么其回答的问题就是：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在诊断为癌症的一堆人中，到底有多少人真得了癌症？</span><br></pre></td></tr></table></figure>
<p>如用Recall对系统进行评估，那么其回答的问题就是：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在一堆得了癌症的病人中，到底有多少人能被成功检测出癌症？</span><br></pre></td></tr></table></figure>
<p>如用Accuracy对系统进行评估，那么其回答的问题就是：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在一堆癌症病人和正常人中，有多少人被系统给出了正确诊断结果（患癌或没患癌）？</span><br></pre></td></tr></table></figure>
<p><strong>OK，那啥时候应该更注重Recall而不是Precision呢？</strong></p>
<blockquote>
<p>当False Negative (FN)的成本代价很高 (后果很严重)，希望尽量避免产生FN时，应该着重考虑提高Recall指标。</p>
</blockquote>
<p>在上述例子里，False Negative是得了癌症的病人没有被诊断出癌症，这种情况是最应该避免的。我们宁可把健康人误诊为癌症 (FP)，也不能让真正患病的人检测不出癌症 (FN) 而耽误治疗离世。在这里，癌症诊断系统的目标是：尽可能提高Recall值，哪怕牺牲一部分Precision。</p>
<p><strong>那啥时候应该更注重Precision而不是Recall呢？</strong></p>
<blockquote>
<p>当False Positive (FP)的成本代价很高 (后果很严重)时，即期望尽量避免产生FP时，应该着重考虑提高Precision指标。</p>
</blockquote>
<p>以垃圾邮件屏蔽系统为例，垃圾邮件为Positive，正常邮件为Negative，False Positive是把正常邮件识别为垃圾邮件，这种情况是最应该避免的（你能容忍一封重要工作邮件直接进了垃圾箱，被不知不觉删除吗？）。我们宁可把垃圾邮件标记为正常邮件 (FN)，也不能让正常邮件直接进垃圾箱 (FP)。在这里，垃圾邮件屏蔽系统的目标是：尽可能提高Precision值，哪怕牺牲一部分recall。</p>
<p>而F1-score是Precision和Recall两者的综合。</p>
<p>举个更有意思的例子（我拍脑袋想出来的，绝对原创哈），假设检察机关想将罪犯捉拿归案，需要对所有人群进行分析，以判断某人犯了罪（Positive），还是没犯罪（Negative）。显然，检察机关希望不漏掉一个罪人（提高recall），也不错怪一个好人（提高precision），所以就需要同时权衡recall和precision两个指标。</p>
<p>尤其在上个世纪，中国司法体制会更偏向Recall，即「天网恢恢，疏而不漏，任何罪犯都插翅难飞」。而西方司法系统会更偏向Precision，即「绝不冤枉一个好人，但是难免有罪犯成为漏网之鱼，逍遥法外」。到底是哪种更好呢？显然，极端并不可取。Precision和Recall都应该越高越好，也就是F1应该越高越好。</p>
<p>呼，二分类问题的常见指标和试用场景终于讲完了。咦，说好的快速回顾呢？</p>
<h2 id="多分类模型的常见指标解析"><a href="#多分类模型的常见指标解析" class="headerlink" title="多分类模型的常见指标解析"></a>多分类模型的常见指标解析</h2><p>在多分类（大于两个类）问题中，假设我们要开发一个动物识别系统，来区分输入图片是猫，狗还是猪。给定分类器一堆动物图片，产生了如下结果混淆矩阵。</p>
<p><img src="https://pic4.zhimg.com/80/v2-e1cf922d05b7e1bf266620577e6fd253_720w.jpg" alt="img"></p>
<p>在混淆矩阵中，正确的分类样本（Actual label = Predicted label）分布在左上到右下的对角线上。其中，Accuracy的定义为分类正确（对角线上）的样本数与总样本数的比值。<strong>Accuracy度量的是全局样本预测情况。而对于Precision和Recall而言，每个类都需要单独计算其Precision和Recall</strong>。</p>
<p><img src="https://pic4.zhimg.com/80/v2-77e85aad7db38c1f4a2116af5fb10a5b_720w.jpg" alt="img"></p>
<p>比如，对类别「猪」而言，其Precision和Recall分别为:</p>
<p><img src="https://www.zhihu.com/equation?tex=Precision+%3D+%5Cfrac%7BTP%7D%7BTP%2BFP%7D+%3D+%5Cfrac%7B20%7D%7B20%2B50%7D+%3D+2%2F7" alt="[公式]"></p>
<p><img src="https://www.zhihu.com/equation?tex=Recall+%3D+%5Cfrac%7BTP%7D%7BTP%2BFN%7D+%3D+%5Cfrac%7B20%7D%7B20%2B10%7D+%3D+2%2F3" alt="[公式]"></p>
<p>也就是，</p>
<p><img src="https://www.zhihu.com/equation?tex=P_%7Bcat%7D%3D8%2F15%2C+P_%7Bdog%7D+%3D+17%2F23%2CP_%7Bpig%7D%3D2%2F7" alt="[公式]"> （P代表Precision）</p>
<p><img src="https://www.zhihu.com/equation?tex=R_%7Bcat%7D%3D4%2F7%2C+R_%7Bdog%7D+%3D+17%2F32%2CR_%7Bpig%7D%3D2%2F3" alt="[公式]"> （R代表Recall）</p>
<p>如果想评估该识别系统的总体功能，必须考虑猫、狗、猪三个类别的综合预测性能。那么，<strong>到底要怎么综合这三个类别的Precision呢？</strong>是简单加起来做平均吗？通常来说， 我们有如下几种解决方案（也可参考<a href="https://link.zhihu.com/?target=https%3A//scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html">scikit-learn官网</a>）：</p>
<ol>
<li><strong>Macro-average方法</strong></li>
</ol>
<p>该方法最简单，直接将不同类别的评估指标（Precision/ Recall/ F1-score）加起来求平均，给所有类别相同的权重。<strong>该方法能够平等看待每个类别，但是它的值会受稀有类别影响。</strong></p>
<p><img src="https://www.zhihu.com/equation?tex=%5Ctext%7BMacro-Precision%7D+%3D+%5Cfrac%7B%7BP%7D_%7Bcat%7D+%2BP_%7Bdog%7D++%2BP_%7Bpig%7D+%7D%7B3%7D+%3D+0.5194" alt="[公式]"></p>
<p><img src="https://www.zhihu.com/equation?tex=%5Ctext%7BMacro-Recall%7D+%3D+%5Cfrac%7BR_%7Bcat%7D+%2B+R_%7Bdog%7D++%2BR_%7Bpig%7D+%7D%7B3%7D+%3D+0.5898" alt="[公式]"></p>
<p><strong>2. Weighted-average方法</strong></p>
<p>该方法给不同类别不同权重（权重根据该类别的真实分布比例确定），每个类别乘权重后再进行相加。<strong>该方法考虑了类别不平衡情况，它的值更容易受到常见类（majority class）的影响</strong>。</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Ctext%7BW%7D_%7Bcat%7D+%3A+%5Ctext%7BW%7D_%7Bdog%7D+%3A+%5Ctext%7BW%7D_%7Bpig%7D+%3D+%5Ctext%7BN%7D_%7Bcat%7D+%3A+%5Ctext%7BN%7D_%7Bdog%7D+%3A%5Ctext%7BN%7D_%7Bpig%7D++%3D+%5Cfrac%7B7%7D%7B26%7D+%3A+%5Cfrac%7B16%7D%7B26%7D%3A+%5Cfrac%7B3%7D%7B26%7D" alt="[公式]"> (W代表权重，N代表样本在该类别下的真实数目)</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Ctext%7BWeighted-Precision%7D+%3D+%7BP%7D_%7Bcat%7D%5Ctimes+W_%7Bcat%7D+%2B++%7BP%7D_%7Bdog%7D%5Ctimes+W_%7Bdog%7D+%2B++%7BP%7D_%7Bpig%7D%5Ctimes+W_%7Bpig%7D+%3D+0.6314" alt="[公式]"></p>
<p><img src="https://www.zhihu.com/equation?tex=%5Ctext%7BWeighted-Recall%7D+%3D+%7BR%7D_%7Bcat%7D%5Ctimes+W_%7Bcat%7D+%2B++%7BR%7D_%7Bdog%7D%5Ctimes+W_%7Bdog%7D+%2B++%7BR%7D_%7Bpig%7D%5Ctimes+W_%7Bpig%7D+%3D+0.5577" alt="[公式]"></p>
<p><strong>3. Micro-average方法</strong></p>
<p>该方法把每个类别的TP, FP, FN先相加之后，在根据二分类的公式进行计算。</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Ctext%7BMicro-Precision%7D+%3D+%5Cfrac%7B%7BTP%7D_%7Bcat%7D+%2B+%7BTP%7D_%7Bdog%7D+%2B+%7BTP%7D_%7Bpig%7D%7D%7B+%7BTP%7D_%7Bcat%7D+%2B+%7BTP%7D_%7Bdog%7D+%2B+%7BTP%7D_%7Bpig%7D%2B++%7BFP%7D_%7Bcat%7D+%2B+%7BFP%7D_%7Bdog%7D+%2B+%7BFP%7D_%7Bpig%7D%7D+%3D+0.5577+" alt="[公式]"></p>
<p><img src="https://www.zhihu.com/equation?tex=%5Ctext%7BMicro-Recall%7D+%3D+%5Cfrac%7B%7BTP%7D_%7Bcat%7D+%2B+%7BTP%7D_%7Bdog%7D+%2B+%7BTP%7D_%7Bpig%7D%7D%7B+%7BTP%7D_%7Bcat%7D+%2B+%7BTP%7D_%7Bdog%7D+%2B+%7BTP%7D_%7Bpig%7D%2B++%7BFN%7D_%7Bcat%7D+%2B+%7BFN%7D_%7Bdog%7D+%2B+%7BFN%7D_%7Bpig%7D%7D%3D0.5577" alt="[公式]"></p>
<p>其中，特别有意思的是，<strong>Micro-precision和Micro-recall竟然始终相同！</strong>这是为啥呢？</p>
<p>这是因为在某一类中的False Positive样本，一定是其他某类别的False Negative样本。听起来有点抽象？举个例子，比如说系统错把「狗」预测成「猫」，那么对于狗而言，其错误类型就是False Negative，对于猫而言，其错误类型就是False Positive。于此同时，Micro-precision和Micro-recall的数值都等于Accuracy，因为它们计算了对角线样本数和总样本数的比值，总结就是：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Ctext%7BMicro-Precision%7D+%3D+%5Ctext%7BMicro-Recall%7D+%3D+%5Ctext%7BMicro-F1+score%7D+%3D+%5Ctext%7BAccuracy%7D+" alt="[公式]"></p>
<p>最后，我们运行一下代码，检验手动计算结果是否和Sklearn包结果一致：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import seaborn as sns</span><br><span class="line">from sklearn.metrics import confusion_matrix</span><br><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from sklearn.metrics import accuracy_score, average_precision_score,precision_score,f1_score,recall_score</span><br><span class="line"></span><br><span class="line"># create confusion matrix</span><br><span class="line">y_true = np.array([-1]*70 + [0]*160 + [1]*30)</span><br><span class="line">y_pred = np.array([-1]*40 + [0]*20 + [1]*20 + </span><br><span class="line">                  [-1]*30 + [0]*80 + [1]*30 + </span><br><span class="line">                  [-1]*5 + [0]*15 + [1]*20)</span><br><span class="line">cm = confusion_matrix(y_true, y_pred)</span><br><span class="line">conf_matrix = pd.DataFrame(cm, index=[&#x27;Cat&#x27;,&#x27;Dog&#x27;,&#x27;Pig&#x27;], columns=[&#x27;Cat&#x27;,&#x27;Dog&#x27;,&#x27;Pig&#x27;])</span><br><span class="line"></span><br><span class="line"># plot size setting</span><br><span class="line">fig, ax = plt.subplots(figsize = (4.5,3.5))</span><br><span class="line">sns.heatmap(conf_matrix, annot=True, annot_kws=&#123;&quot;size&quot;: 19&#125;, cmap=&quot;Blues&quot;)</span><br><span class="line">plt.ylabel(&#x27;True label&#x27;, fontsize=18)</span><br><span class="line">plt.xlabel(&#x27;Predicted label&#x27;, fontsize=18)</span><br><span class="line">plt.xticks(fontsize=18)</span><br><span class="line">plt.yticks(fontsize=18)</span><br><span class="line">plt.savefig(&#x27;confusion.pdf&#x27;, bbox_inches=&#x27;tight&#x27;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://pic2.zhimg.com/80/v2-344f35ae60c0ad5eeb24a19aefa92f45_720w.jpg" alt="img"></p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">print(&#x27;------Weighted------&#x27;)</span><br><span class="line">print(&#x27;Weighted precision&#x27;, precision_score(y_true, y_pred, average=&#x27;weighted&#x27;))</span><br><span class="line">print(&#x27;Weighted recall&#x27;, recall_score(y_true, y_pred, average=&#x27;weighted&#x27;))</span><br><span class="line">print(&#x27;Weighted f1-score&#x27;, f1_score(y_true, y_pred, average=&#x27;weighted&#x27;))</span><br><span class="line">print(&#x27;------Macro------&#x27;)</span><br><span class="line">print(&#x27;Macro precision&#x27;, precision_score(y_true, y_pred, average=&#x27;macro&#x27;))</span><br><span class="line">print(&#x27;Macro recall&#x27;, recall_score(y_true, y_pred, average=&#x27;macro&#x27;))</span><br><span class="line">print(&#x27;Macro f1-score&#x27;, f1_score(y_true, y_pred, average=&#x27;macro&#x27;))</span><br><span class="line">print(&#x27;------Micro------&#x27;)</span><br><span class="line">print(&#x27;Micro precision&#x27;, precision_score(y_true, y_pred, average=&#x27;micro&#x27;))</span><br><span class="line">print(&#x27;Micro recall&#x27;, recall_score(y_true, y_pred, average=&#x27;micro&#x27;))</span><br><span class="line">print(&#x27;Micro f1-score&#x27;, f1_score(y_true, y_pred, average=&#x27;micro&#x27;))</span><br></pre></td></tr></table></figure>
<p><img src="https://pic2.zhimg.com/80/v2-499a45ce0ed22859d425ca82467b813d_720w.jpg" alt="img"></p>
<p>运算结果完全一致，OK，机器学习多分类模型的常见评估指标已经基本介绍完毕，大家如果有疑问尽情在评论区留言哈，我争取尽快回复大家 :)</p>
</div><div class="article-licensing box"><div class="licensing-title"><p><a href="https://paddeyzhang.tech/2023/02/19/多分类模型Accuracy, Precision, Recall和F1-score的超级无敌深入探讨/">https://paddeyzhang.tech/2023/02/19/多分类模型Accuracy, Precision, Recall和F1-score的超级无敌深入探讨/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>paddeyzhang</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2023-02-19</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2023-02-19</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2023/02/21/k%E8%BF%91%E9%82%BB%E6%B3%95/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">k近邻法</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2023/02/19/%E4%BB%80%E4%B9%88%E6%98%AF%E5%B7%AE%E5%88%86%E9%9A%90%E7%A7%81/"><span class="level-item"> </span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="https://polaris-973.oss-cn-shenzhen.aliyuncs.com/img/b9c9db0f589cd855eb655fce4054665.jpg" alt="PaddeyZhang"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">PaddeyZhang</p><p class="is-size-6 is-block">Master of Computer Science and Technology (GDUT)</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>GuangZhou, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">36</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">9</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">8</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/polaris-973" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="mailto:paddeyzhang@gmail.com"><i class="fas fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/polaris-973"><i class="fab fa-github"></i></a></div></div></div><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Latex/"><span class="level-start"><span class="level-item">Latex</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/OpenCV/"><span class="level-start"><span class="level-item">OpenCV</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%88%9B%E5%BB%BA%E5%8D%9A%E5%AE%A2-Github-hexo/"><span class="level-start"><span class="level-item">创建博客_Github_hexo</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%88%B7%E9%A2%98/"><span class="level-start"><span class="level-item">刷题</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E5%AD%A6%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">数学理论学习</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"><span class="level-start"><span class="level-item">数据挖掘</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">机器学习 深度学习</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Pytorch/"><span class="level-start"><span class="level-item">机器学习 深度学习 Pytorch</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"><span class="level-start"><span class="level-item">统计学习方法</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-03-02T12:05:14.000Z">2023-03-02</time></p><p class="title"><a href="/2023/03/02/%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/">逻辑斯谛回归与最大熵模型</a></p><p class="categories"><a href="/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/">统计学习方法</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-02-26T04:50:51.000Z">2023-02-26</time></p><p class="title"><a href="/2023/02/26/%E5%86%B3%E7%AD%96%E6%A0%91/">决策树</a></p><p class="categories"><a href="/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/">统计学习方法</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-02-24T08:12:30.000Z">2023-02-24</time></p><p class="title"><a href="/2023/02/24/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95/">朴素贝叶斯法</a></p><p class="categories"><a href="/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/">统计学习方法</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-02-21T15:59:45.000Z">2023-02-21</time></p><p class="title"><a href="/2023/02/21/k%E8%BF%91%E9%82%BB%E6%B3%95/">k近邻法</a></p><p class="categories"><a href="/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/">统计学习方法</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-02-19T14:25:29.963Z">2023-02-19</time></p><p class="title"><a href="/2023/02/19/%E5%A4%9A%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8BAccuracy,%20Precision,%20Recall%E5%92%8CF1-score%E7%9A%84%E8%B6%85%E7%BA%A7%E6%97%A0%E6%95%8C%E6%B7%B1%E5%85%A5%E6%8E%A2%E8%AE%A8/"> </a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2023/03/"><span class="level-start"><span class="level-item">March 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/02/"><span class="level-start"><span class="level-item">February 2023</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/12/"><span class="level-start"><span class="level-item">December 2021</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/11/"><span class="level-start"><span class="level-item">November 2021</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/10/"><span class="level-start"><span class="level-item">October 2021</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Latex/"><span class="tag">Latex</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2-%E6%95%B0%E5%AD%A6%E7%90%86%E8%AE%BA/"><span class="tag">傅里叶变换 数学理论</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%88%B7%E9%A2%98-leetcode-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"><span class="tag">刷题 leetcode 数据结构</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-%E6%95%B0%E5%AD%A6%E7%90%86%E8%AE%BA/"><span class="tag">数据挖掘 数学理论</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Pytorch/"><span class="tag">机器学习 深度学习 Pytorch</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%B3%B0%E5%8B%92%E5%B1%95%E5%BC%80%E5%BC%8F-%E6%95%B0%E5%AD%A6%E7%90%86%E8%AE%BA/"><span class="tag">泰勒展开式 数学理论</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0-%E6%95%B0%E5%AD%A6%E7%90%86%E8%AE%BA/"><span class="tag">线性代数 数学理论</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"><span class="tag">统计学习方法</span><span class="tag">5</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="https://polaris-973.oss-cn-shenzhen.aliyuncs.com/img/b9c9db0f589cd855eb655fce4054665.jpg" alt="Paddey&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2023 paddeyzhang</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>